{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "856d4137-fe8d-4c8b-9eb9-a5e1ec8d3cca",
   "metadata": {},
   "source": [
    "This is a fetcher for the dataset. It gets data and saves them to a folder.\n",
    "\n",
    "First we start withour dataset listing and the folder to save data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27ef73a5-600c-47b6-9f51-5fe3e9feb3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_URL = 'http://www.omdb.org/data'\n",
    "FILE_LIST = [\n",
    "'all_casts.csv.bz2',                  \n",
    "'all_categories.csv.bz2',             \n",
    "'all_characters.csv.bz2',             \n",
    "'all_episodes.csv.bz2',               \n",
    "'all_movies.csv.bz2',                 \n",
    "'all_movieseries.csv.bz2',                      \n",
    "'all_movie_aliases_iso.csv.bz2',      \n",
    "'all_people.csv.bz2',                 \n",
    "'all_people_aliases.csv.bz2',         \n",
    "'all_seasons.csv.bz2',                \n",
    "'all_series.csv.bz2',                 \n",
    "'all_votes.csv.bz2',                  \n",
    "'category_names.csv.bz2',             \n",
    "'image_ids.csv.bz2',                  \n",
    "'image_licenses.csv.bz2',             \n",
    "'job_names.csv.bz2',                  \n",
    "'movie_abstracts_de.csv.bz2',         \n",
    "'movie_abstracts_en.csv.bz2',         \n",
    "'movie_abstracts_es.csv.bz2',         \n",
    "'movie_abstracts_fr.csv.bz2',         \n",
    "'movie_categories.csv.bz2',           \n",
    "'movie_content_updates.csv.bz2',      \n",
    "'movie_countries.csv.bz2',            \n",
    "'movie_details.csv.bz2',              \n",
    "'movie_keywords.csv.bz2',             \n",
    "'movie_languages.csv.bz2',            \n",
    "'movie_links.csv.bz2',                \n",
    "'movie_references.csv.bz2',           \n",
    "'people_links.csv.bz2',               \n",
    "'trailers.csv.bz2'     \n",
    "]\n",
    "\n",
    "DATASET_FOLDER = 'raw_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91466025-285d-435b-9940-1e8f9e086a3a",
   "metadata": {},
   "source": [
    "Our fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98254574-7114-4ad7-8a4b-0b11fc76f026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all_casts.csv.bz2\n",
      "Processing all_categories.csv.bz2\n",
      "Processing all_characters.csv.bz2\n",
      "Processing all_episodes.csv.bz2\n",
      "Processing all_movies.csv.bz2\n",
      "Processing all_movieseries.csv.bz2\n",
      "Processing all_movie_aliases_iso.csv.bz2\n",
      "Processing all_people.csv.bz2\n",
      "Processing all_people_aliases.csv.bz2\n",
      "Processing all_seasons.csv.bz2\n",
      "Processing all_series.csv.bz2\n",
      "Processing all_votes.csv.bz2\n",
      "Processing category_names.csv.bz2\n",
      "Processing image_ids.csv.bz2\n",
      "Processing image_licenses.csv.bz2\n",
      "Processing job_names.csv.bz2\n",
      "Processing movie_abstracts_de.csv.bz2\n",
      "Processing movie_abstracts_en.csv.bz2\n",
      "Processing movie_abstracts_es.csv.bz2\n",
      "Processing movie_abstracts_fr.csv.bz2\n",
      "Processing movie_categories.csv.bz2\n",
      "Processing movie_content_updates.csv.bz2\n",
      "Processing movie_countries.csv.bz2\n",
      "Processing movie_details.csv.bz2\n",
      "Processing movie_keywords.csv.bz2\n",
      "Processing movie_languages.csv.bz2\n",
      "Processing movie_links.csv.bz2\n",
      "Processing movie_references.csv.bz2\n",
      "Processing people_links.csv.bz2\n",
      "Processing trailers.csv.bz2\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if os.path.isdir(DATASET_FOLDER):\n",
    "    shutil.rmtree(DATASET_FOLDER)\n",
    "\n",
    "os.mkdir(DATASET_FOLDER)\n",
    "\n",
    "# https://stackoverflow.com/questions/16694907/download-large-file-in-python-with-requests\n",
    "for file_name in FILE_LIST:\n",
    "    print(f\"Processing {file_name}\")\n",
    "    with requests.get(MASTER_URL+\"/\"+file_name, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(DATASET_FOLDER+\"/\"+file_name, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                # If you have chunk encoded response uncomment if\n",
    "                # and set chunk_size parameter to None.\n",
    "                #if chunk: \n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb9f88-edd6-4f7f-8359-92c50fafe6fa",
   "metadata": {},
   "source": [
    "Here we put the code that does the preprocessing described in https://github.com/wey-gu/movie-recommendation-dataset/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c3d7c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SQLAlchemy in .\\.venv\\lib\\site-packages (2.0.35)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in .\\.venv\\lib\\site-packages (from SQLAlchemy) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in .\\.venv\\lib\\site-packages (from SQLAlchemy) (3.1.1)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.1.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in .\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in .\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in .\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Downloading numpy-2.1.2-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 6.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.1/12.6 MB 8.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.0/12.6 MB 8.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.8/12.6 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 8.8 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, pandas\n",
      "Successfully installed numpy-2.1.2 pandas-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install SQLAlchemy\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c96d21c-aadb-4f1d-ba4a-fe3d502a0e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing all_casts.csv.bz2\n",
      "Importing all_categories.csv.bz2\n",
      "Importing all_characters.csv.bz2\n",
      "Importing all_episodes.csv.bz2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VasilisAnagnostopoul\\AppData\\Local\\Temp\\ipykernel_21800\\386281595.py:37: DtypeWarning: Columns (2,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(multi_line_csv, quotechar='\"', quoting=csv.QUOTE_ALL, index_col=False, delimiter=',')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing all_movies.csv.bz2\n",
      "Importing all_movieseries.csv.bz2\n",
      "Importing all_movie_aliases_iso.csv.bz2\n",
      "Importing all_people.csv.bz2\n",
      "Importing all_people_aliases.csv.bz2\n",
      "Importing all_seasons.csv.bz2\n",
      "Importing all_series.csv.bz2\n",
      "Importing all_votes.csv.bz2\n",
      "Importing category_names.csv.bz2\n",
      "Importing image_ids.csv.bz2\n",
      "Importing image_licenses.csv.bz2\n",
      "Importing job_names.csv.bz2\n",
      "Importing movie_abstracts_de.csv.bz2\n",
      "Importing movie_abstracts_en.csv.bz2\n",
      "Importing movie_abstracts_es.csv.bz2\n",
      "Importing movie_abstracts_fr.csv.bz2\n",
      "Importing movie_categories.csv.bz2\n",
      "Importing movie_content_updates.csv.bz2\n",
      "Importing movie_countries.csv.bz2\n",
      "Importing movie_details.csv.bz2\n",
      "Importing movie_keywords.csv.bz2\n",
      "Importing movie_languages.csv.bz2\n",
      "Importing movie_links.csv.bz2\n",
      "Importing movie_references.csv.bz2\n",
      "Importing people_links.csv.bz2\n",
      "Importing trailers.csv.bz2\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import csv\n",
    "import io\n",
    "import bz2\n",
    "\n",
    "CONNECTION_STRING = \"postgresql+psycopg2://postgres:postgres@localhost:5432/postgres\"\n",
    "SCHEMA_NAME = 'omdbs'\n",
    "\n",
    "engine = sqlalchemy.create_engine(CONNECTION_STRING)\n",
    "\n",
    "# if engine.dialect.has_schema(engine, SCHEMA_NAME):\n",
    "#     engine.execute(f\"DROP SCHEMA {SCHEMA_NAME} CASCADE;\")\n",
    "\n",
    "inspector = sqlalchemy.inspect(engine)\n",
    "exists_schema = False\n",
    "if SCHEMA_NAME in inspector.get_schema_names():\n",
    "    print(f\"{SCHEMA_NAME} schema exists\")\n",
    "    exists_schema = True        \n",
    "\n",
    "with engine.connect() as connection:\n",
    "    if exists_schema:\n",
    "        result = connection.execute(sqlalchemy.schema.DropSchema(SCHEMA_NAME, cascade=True))\n",
    "    connection.execute(sqlalchemy.schema.CreateSchema(SCHEMA_NAME))\n",
    "    connection.commit()\n",
    "\n",
    "for file_name in FILE_LIST:\n",
    "    print(f\"Importing {file_name}\")\n",
    "    file_path = DATASET_FOLDER+\"/\"+file_name\n",
    "\n",
    "    with bz2.open(file_path, \"rb\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    text_file_content = content.decode('utf-8').replace('\\\\\\\"', \"\\\\\\'\")\n",
    "\n",
    "    multi_line_csv = io.StringIO(text_file_content)\n",
    "    df = pd.read_csv(multi_line_csv, quotechar='\"', quoting=csv.QUOTE_ALL, index_col=False, delimiter=',')\n",
    "    table_name = file_name.split('.')[0]\n",
    "    df.to_sql(table_name, engine, schema=SCHEMA_NAME, if_exists='replace', index=False)\n",
    "\n",
    "    del df\n",
    "    del text_file_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
